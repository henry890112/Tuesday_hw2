# Generate the data that divided into test, train and annotations

```python
python data_generator.py
```

![1667918923616.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/11c70c77-c3b4-42b7-a8af-c7c1535fd4c9/1667918923616.png)

# Transform the data to .odgt

```bash
python trans.py
```

# Training own model

1. use `trans.py` to convert the image path to .odgt
2. use your own `custom.yaml`
    - **The .odgt path that consist in this .yaml is generated by trans.py**
3. Need change ：
    1. num_class that you have
    2. list_train and list_val of tour .odgt
    3. batch size, iterations and epoch by your own
    4. output DIR

```bash
python3 train.py --gpus 1 --cfg config/custom.yaml
```

- To choose which gpus to use, you can either do `--gpus 0-3`, or `--gpus 0,1,2,3`
- To change the config by  `--cfg your config path`

# Collect the data in habitat

Use the new_load.py (depend on the HW1’s load.py) to collect the RGB, depth and annotationdata

```bash
python new_load.py
```

# Transform the data to .odgt

```bash
python my_trans.py
```

- [trans.py](http://trans.py) and my_trans.py is different

# Generate the predicted semantic segmentation and colorize the ground truth and estimated annotaions

```bash
python eval_multipro.py --cfg config/apartment0.yaml
```

- To choose which gpus to use, you can either do `--gpus 0-3`, or `--gpus 0,1,2,3`\
- To change the config by  `--cfg your config path`
- **The .odgt path that consist in this .yaml is generated by my_trans.py**

# Reconstruct the environment by semantic segmentation

```bash
python new_reconstruct.py
```

- need to adjust the path of the result image
